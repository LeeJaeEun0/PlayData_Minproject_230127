{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 6000,
     "status": "ok",
     "timestamp": 1674737379812,
     "user": {
      "displayName": "홍월",
      "userId": "09425878199732671088"
     },
     "user_tz": -540
    },
    "id": "DlXtbUaVDsQI"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.applications.mobilenet_v2 import preprocess_input\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19150,
     "status": "ok",
     "timestamp": 1674737405829,
     "user": {
      "displayName": "홍월",
      "userId": "09425878199732671088"
     },
     "user_tz": -540
    },
    "id": "3YZFiSd1H_G7",
    "outputId": "79993434-2c96-4a57-c70d-4a7544b117d9"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 284,
     "status": "ok",
     "timestamp": 1674737526110,
     "user": {
      "displayName": "홍월",
      "userId": "09425878199732671088"
     },
     "user_tz": -540
    },
    "id": "vfUK6O9LIII9"
   },
   "outputs": [],
   "source": [
    "# 경로 수정할 것\n",
    "# face_dnn_model_name = '/content/gdrive/MyDrive/Project/Mask_Detection_Model/res10_300x300_ssd_iter_140000.caffemodel'\n",
    "# prototxt_name = '/content/gdrive/MyDrive/Project/Mask_Detection_Model/deploy.prototxt.txt'\n",
    "\n",
    "face_dnn_model_name = 'C:/mask/res10_300x300_ssd_iter_140000.caffemodel'\n",
    "prototxt_name = 'C:/mask/deploy.prototxt.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 304,
     "status": "ok",
     "timestamp": 1674737711272,
     "user": {
      "displayName": "홍월",
      "userId": "09425878199732671088"
     },
     "user_tz": -540
    },
    "id": "yzC10eopJLTJ"
   },
   "outputs": [],
   "source": [
    "# 변수 설정\n",
    "min_confidence = 0.3 \n",
    "frame_width = 700 # 열린 창의 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 3791,
     "status": "ok",
     "timestamp": 1674738766474,
     "user": {
      "displayName": "홍월",
      "userId": "09425878199732671088"
     },
     "user_tz": -540
    },
    "id": "ZfGmQVuONKbo"
   },
   "outputs": [],
   "source": [
    "# 모델 객체 생성\n",
    "face_detect_model = cv2.dnn.readNetFromCaffe(prototxt_name, face_dnn_model_name)\n",
    "# mask_detect_model = load_model('/content/gdrive/MyDrive/Project/Mask_Detection_Model/mask_detector.model')\n",
    "mask_detect_model = load_model('C:/mask/mask_detector.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 277,
     "status": "ok",
     "timestamp": 1674739453610,
     "user": {
      "displayName": "홍월",
      "userId": "09425878199732671088"
     },
     "user_tz": -540
    },
    "id": "viLAWXljIlVK"
   },
   "outputs": [],
   "source": [
    "def detectAndDisplay(frame, type):\n",
    "    # frame_width 에 맞춰서 image resize - 화면에 영상을 띄울때 크기설정\n",
    "    (height, width) = frame.shape[:2]\n",
    "    ratio = frame_width / width\n",
    "    dimension = (frame_width, int(height * ratio))\n",
    "    frame = cv2.resize(frame, dimension, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    # 이미지를 300 x 300으로 size 조정하고 blob 만들기\n",
    "    # blob = cv2.dnn.blobFromImage(img, scalefactor=1., size=(300, 300), mean=(104., 177., 123.))\n",
    "    # \n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), scalefactor=1.0,\n",
    "                                 size=(300, 300), mean=(104.0, 177.0, 123.0))\n",
    "    \n",
    "    # blob 모델에 넣고 얼굴 detection 수행\n",
    "    face_detect_model.setInput(blob)\n",
    "    face_detections = face_detect_model.forward()\n",
    "\n",
    "    result_frame = frame.copy()\n",
    "\n",
    "    # Detections 한 수만큼 루프 돌기\n",
    "    for i in range(0, face_detections.shape[2]):\n",
    "        confidence = face_detections[0, 0, i, 2] # confidence는 detection한 확률\n",
    "\n",
    "        # min_confidence 보다 큰 경우에만 detection으로 인정함\n",
    "        if confidence > min_confidence:\n",
    "            print('Face Detection Complete')\n",
    "            # box 좌표 구하기\n",
    "            box = face_detections[0, 0, i, 3:7] * np.array([frame_width, int(height * ratio), frame_width, int(height * ratio)])\n",
    "            (x1, y1, x2, y2) = box.astype('int')\n",
    "            \n",
    "            # 얼굴 이미지 자르기\n",
    "            face = frame[y1:y2, x1:x2]\n",
    "\n",
    "            # 얼굴 이미지를 입력값에 맞게 변형\n",
    "            face_input = cv2.resize(face, dsize=(224, 224))\n",
    "            face_input = cv2.cvtColor(face_input, cv2.COLOR_BGR2RGB)\n",
    "            face_input = preprocess_input(face_input)\n",
    "            face_input = np.expand_dims(face_input, axis=0)\n",
    "\n",
    "            # 얼굴 이미지를 모델에 넣기\n",
    "            mask, nomask = mask_detect_model.predict(face_input).squeeze()\n",
    "\n",
    "            # 마스크 인식 결과 비교\n",
    "            if mask > nomask:\n",
    "                color = (0, 255, 0)\n",
    "                label = 'Mask %d%%' % (mask * 100)\n",
    "            else:\n",
    "                color = (0, 0, 255)\n",
    "                label = 'No Mask %d%%' % (nomask * 100)\n",
    "\n",
    "            # 얼굴에 사각형 그리기\n",
    "            cv2.rectangle(result_frame, pt1=(x1, y1), pt2=(x2, y2), thickness=2, color=color, lineType=cv2.LINE_AA)\n",
    "            cv2.putText(result_frame, text=label, org=(x1, y1 - 10), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.8, color=color, thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "    # 결과 출력\n",
    "    if type == 'vedio':\n",
    "        global writer\n",
    "        if writer is None:\n",
    "            fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "            out = cv2.VideoWriter('output.mp4', fourcc, frame.get(cv2.CAP_PROP_FPS), (frame.shape[1], frame.shape[0]))\n",
    "        \n",
    "        # disk에 frame을 write\n",
    "        if writer is not None:\n",
    "            out.write(result_frame)\n",
    "    \n",
    "    # camera인 경우\n",
    "    else:\n",
    "        cv2.imshow('camera', result_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 296,
     "status": "ok",
     "timestamp": 1674739961109,
     "user": {
      "displayName": "홍월",
      "userId": "09425878199732671088"
     },
     "user_tz": -540
    },
    "id": "BjbA9OFdNfPs",
    "outputId": "d6ce3da4-2db4-40a1-cdd1-9200ad6bd102"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Detection Complete\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "Face Detection Complete\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "Face Detection Complete\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "Face Detection Complete\n",
      "1/1 [==============================] - 0s 239ms/step\n",
      "Face Detection Complete\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "Face Detection Complete\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "Face Detection Complete\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "Face Detection Complete\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "Face Detection Complete\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "Face Detection Complete\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "Face Detection Complete\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "Face Detection Complete\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "Face Detection Complete\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "Face Detection Complete\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "Face Detection Complete\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "Face Detection Complete\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "Face Detection Complete\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "Face Detection Complete\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "Face Detection Complete\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "Face Detection Complete\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "Face Detection Complete\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "Face Detection Complete\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "Face Detection Complete\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "Face Detection Complete\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "Face Detection Complete\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "Face Detection Complete\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "Face Detection Complete\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "Face Detection Complete\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "Face Detection Complete\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "Face Detection Complete\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "Face Detection Complete\n",
      "1/1 [==============================] - 0s 228ms/step\n",
      "Face Detection Complete\n",
      "1/1 [==============================] - 0s 231ms/step\n",
      "Face Detection Complete\n",
      "1/1 [==============================] - 0s 211ms/step\n"
     ]
    }
   ],
   "source": [
    "# 동영상 입력(vedio), 카메라 입력(camera)\n",
    "# cap = cv2.VideoCapture('path') # 비디오에 모델을 적용하고 싶은 경우\n",
    "cap = cv2.VideoCapture(0) # 비디오 캡처 객체를 생성(캠을 위해 필수)\n",
    "\n",
    "# cap.set(id, value)는 프로퍼티 변경 \n",
    "# CAP_PROP_FRAME_WIDTH 프레임 폭\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, frame_width)  # 프레임 폭을 현재 창의 크기로\n",
    "# CAP_PROP_FRAME_HEIGHT프레임 높이\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, frame_width) # 프레임 높이을 현재 창의 크기로\n",
    "\n",
    "if cap.isOpened(): # 객체 초기화 확인 - 장치와 잘 연결되었는지 확인\n",
    "    while True:\n",
    "        \n",
    "        # cap.read()는 영상 프레임 읽기 \n",
    "        # ret는 프레임 읽기 성공 또는 실패 여부\n",
    "        # img는 프레임 이미지, NumPy() 배열 또는 None()\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if ret:\n",
    "            detectAndDisplay(frame, 'cam')\n",
    "            # waitKey() 는 일정 시간 지연 후 함수를 빠져 나옴\n",
    "            #화면을 보는데 지연시간 필요 - 너무 빠르면 눈을 볼 수 없어서\n",
    "            \n",
    "            # 1ms 동안 키 입력 대기 - 아무 키나 눌렀으면 중지\n",
    "            # 입력이 없으면 자동으로 -1이 들어감 -> -1이 아니면 키를 누른 것\n",
    "            if cv2.waitKey(1) != -1: # if문에서 조건 설정\n",
    "                break\n",
    "        else:\n",
    "            print('no frame!')\n",
    "\n",
    "else:\n",
    "    # 캠을 켤 수 없다는 안내\n",
    "    print(\"can't open camera!\")\n",
    "\n",
    "cap.release() # 캡처 자원 반납\n",
    "# writer.release()\n",
    "cv2.destroyAllWindows() # 창 닫기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M3Eicf-3Qmt-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOUlBxv5gbLnIVZ8hMFRxj2",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
